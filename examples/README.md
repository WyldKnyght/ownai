# Examples

If you want to get started quickly and run your AIs by yourself, please have a look at the [llamacpp](./llamacpp) examples.
These allow you to run your own AIs on your machine with little or no further setup.

## AI provider examples

These examples use APIs from external providers. Your requests will be sent to the provider's servers and the AIs will be executed there.
These AIs are very easy to set up since you only need to sign up for an API key.
Please refer to the privacy policy of the respective providers.

- [ai21](./ai21)
- [aleph_alpha](./aleph_alpha)
- [cohere](./cohere)
- [deepinfra](./deepinfra)
- [forefrontai](./forefrontai)
- [google_palm](./google_palm)
- [gooseai](./gooseai)
- [huggingface_hub](./huggingface_hub)
- [mosaic](./mosaic)
- [nlpcloud](./nlpcloud)
- [openai](./openai)
- [replicate](./replicate)
- [stochasticai](./stochasticai)
- [writer](./writer)

## Infrastructure provider examples

These providers offer you the infrastructure to run your own AI models there. Some also offer some preinstalled models.
Please refer to the privacy policy of the respective providers.

- [anyscale](./anyscale)
- [aviary](./aviary)
- [bananadev](./bananadev)
- [beam](./beam)
- [databricks](./databricks)
- [huggingface_endpoint](./huggingface_endpoint)
- [modal](./modal)
- [vertexai](./vertexai)

## Self-hosting examples

These AIs can be run on your own machines.
Please be aware that large AI models require a lot of resources and cannot be run on every computer.

- [aviary](./aviary)
- [ctransformers](./ctransformers)
- [gpt4all](./gpt4all)
- [huggingface_pipeline](./huggingface_pipeline)
- [huggingface_textgen_inference](./huggingface_textgen_inference)
- [llamacpp](./llamacpp)
- [rwkv](./rwkv)

## Collaborative operation examples

Petals allows you to run large language models collaboratively â€” you load a small part of the model, then team up with people serving the other parts.

- [petals](./petals)
